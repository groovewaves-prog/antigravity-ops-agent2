import streamlit as st
import graphviz
import os
import time
import google.generativeai as genai
import json
import pandas as pd
from google.api_core import exceptions as google_exceptions

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import run_diagnostic_simulation, generate_remediation_commands, predict_initial_symptoms, generate_fake_log_by_ai
from verifier import verify_log_content, format_verification_report
from inference_engine import LogicalRCA

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Autonomous", page_icon="âš¡", layout="wide")

# ==========================================
# é–¢æ•°å®šç¾©
# ==========================================
def find_target_node_id(topology, node_type=None, layer=None, keyword=None):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰æ¡ä»¶ã«åˆã†ãƒãƒ¼ãƒ‰IDã‚’æ¤œç´¢"""
    for node_id, node in topology.items():
        if node_type and node.type != node_type: continue
        if layer and node.layer != layer: continue
        if keyword:
            hit = False
            if keyword in node_id: hit = True
            for v in node.metadata.values():
                if isinstance(v, str) and keyword in v: hit = True
            if not hit: continue
        return node_id
    return None

def load_config_by_id(device_id):
    """configsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    possible_paths = [f"configs/{device_id}.txt", f"{device_id}.txt"]
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                pass
    return "Config file not found."

def generate_content_with_retry(model, prompt, stream=True, retries=3):
    """503ã‚¨ãƒ©ãƒ¼å¯¾ç­–ã®ãƒªãƒˆãƒ©ã‚¤ä»˜ãç”Ÿæˆé–¢æ•°"""
    for i in range(retries):
        try:
            return model.generate_content(prompt, stream=stream)
        except google_exceptions.ServiceUnavailable:
            if i == retries - 1: raise
            time.sleep(2 * (i + 1))
    return None

def render_topology(alarms, root_cause_candidates):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®æç”» (AIåˆ¤å®šçµæœã‚’åæ˜ )"""
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    alarm_map = {a.device_id: a for a in alarms}
    alarmed_ids = set(alarm_map.keys())
    
    root_cause_ids = {c['id'] for c in root_cause_candidates if c['prob'] > 0.6}
    
    # AIåˆ¤å®šçµæœã®ãƒãƒƒãƒ”ãƒ³ã‚°
    node_status_map = {c['id']: c['type'] for c in root_cause_candidates}
    
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9"
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"
        
        red_type = node.metadata.get("redundancy_type")
        if red_type: label += f"\n[{red_type} Redundancy]"
        vendor = node.metadata.get("vendor")
        if vendor: label += f"\n[{vendor}]"

        status_type = node_status_map.get(node_id, "Normal")
        
        if "Hardware/Physical" in status_type or "Critical" in status_type or "Silent" in status_type:
            color = "#ffcdd2" 
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif "Network/Unreachable" in status_type or "Network/Secondary" in status_type:
            color = "#cfd8dc" 
            fontcolor = "#546e7a"
            label += "\n[Unreachable]"
        elif node_id in alarmed_ids:
            color = "#fff9c4" 
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() 
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity Autonomous Agent")

api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš¡ Scenario Controller")
    SCENARIO_MAP = {
        "åŸºæœ¬ãƒ»åºƒåŸŸéšœå®³": ["æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"],
        "WAN Router": ["4. [WAN] é›»æºéšœå®³ï¼šç‰‡ç³»", "5. [WAN] é›»æºéšœå®³ï¼šä¸¡ç³»", "6. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°", "7. [WAN] FANæ•…éšœ", "8. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "Firewall (Juniper)": ["9. [FW] é›»æºéšœå®³ï¼šç‰‡ç³»", "10. [FW] é›»æºéšœå®³ï¼šä¸¡ç³»", "11. [FW] FANæ•…éšœ", "12. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "L2 Switch": ["13. [L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»", "14. [L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»", "15. [L2SW] FANæ•…éšœ", "16. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "è¤‡åˆãƒ»ãã®ä»–": ["17. [WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN", "18. [Complex] åŒæ™‚å¤šç™ºï¼šFW & AP", "99. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­"]
    }
    selected_category = st.selectbox("å¯¾è±¡ã‚«ãƒ†ã‚´ãƒª:", list(SCENARIO_MAP.keys()))
    selected_scenario = st.radio("ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª:", SCENARIO_MAP[selected_category])
    st.markdown("---")
    if api_key: st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† ---
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"

# å¤‰æ•°åˆæœŸåŒ–
for key in ["live_result", "messages", "chat_session", "trigger_analysis", "verification_result", "generated_report", "verification_log", "last_report_cand_id", "logic_engine"]:
    if key not in st.session_state:
        st.session_state[key] = None if key != "messages" and key != "trigger_analysis" else ([] if key == "messages" else False)

# ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
if not st.session_state.logic_engine:
    st.session_state.logic_engine = LogicalRCA(TOPOLOGY)

# ã‚·ãƒŠãƒªã‚ªåˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒªã‚»ãƒƒãƒˆ
if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []      
    st.session_state.chat_session = None 
    st.session_state.live_result = None 
    st.session_state.trigger_analysis = False
    st.session_state.verification_result = None
    st.session_state.generated_report = None
    st.session_state.verification_log = None 
    st.session_state.last_report_cand_id = None
    if "remediation_plan" in st.session_state: del st.session_state.remediation_plan
    st.rerun()

# ==========================================
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
alarms = []
target_device_id = None
root_severity = "CRITICAL"
is_live_mode = False

# 1. ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
if "Live" in selected_scenario: is_live_mode = True
elif "WANå…¨å›ç·šæ–­" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    if target_device_id: alarms = simulate_cascade_failure(target_device_id, TOPOLOGY)
elif "FWç‰‡ç³»éšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    if target_device_id:
        alarms = [Alarm(target_device_id, "Heartbeat Loss", "WARNING")]
        root_severity = "WARNING"

elif "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³" in selected_scenario:
    target_device_id = "L2_SW_01"
    if target_device_id not in TOPOLOGY:
        target_device_id = find_target_node_id(TOPOLOGY, keyword="L2_SW")
    if target_device_id and target_device_id in TOPOLOGY:
        child_nodes = [nid for nid, n in TOPOLOGY.items() if n.parent_id == target_device_id]
        alarms = [Alarm(child, "Connection Lost", "CRITICAL") for child in child_nodes]
    else:
        st.error("Error: L2 Switch definition not found")

elif "è¤‡åˆéšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    if target_device_id:
        alarms = [
            Alarm(target_device_id, "Power Supply 1 Failed", "CRITICAL"),
            Alarm(target_device_id, "Fan Fail", "WARNING")
        ]
elif "åŒæ™‚å¤šç™º" in selected_scenario:
    fw_node = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    ap_node = find_target_node_id(TOPOLOGY, node_type="ACCESS_POINT")
    alarms = []
    if fw_node: alarms.append(Alarm(fw_node, "Heartbeat Loss", "WARNING"))
    if ap_node: alarms.append(Alarm(ap_node, "Connection Lost", "CRITICAL"))
    target_device_id = fw_node 
else:
    if "[WAN]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    elif "[FW]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    elif "[L2SW]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="SWITCH", layer=4)

    if target_device_id:
        if "é›»æºéšœå®³ï¼šç‰‡ç³»" in selected_scenario:
            alarms = [Alarm(target_device_id, "Power Supply 1 Failed", "WARNING")]
            root_severity = "WARNING"
        elif "é›»æºéšœå®³ï¼šä¸¡ç³»" in selected_scenario:
            if "FW" in target_device_id:
                alarms = [Alarm(target_device_id, "Power Supply: Dual Loss (Device Down)", "CRITICAL")]
            else:
                alarms = simulate_cascade_failure(target_device_id, TOPOLOGY, "Power Supply: Dual Loss (Device Down)")
        elif "BGP" in selected_scenario:
            alarms = [Alarm(target_device_id, "BGP Flapping", "WARNING")]
            root_severity = "WARNING"
        elif "FAN" in selected_scenario:
            alarms = [Alarm(target_device_id, "Fan Fail", "WARNING")]
            root_severity = "WARNING"
        elif "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
            alarms = [Alarm(target_device_id, "Memory High", "WARNING")]
            root_severity = "WARNING"

# 2. æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹åˆ†æ
analysis_results = st.session_state.logic_engine.analyze(alarms)

# 3. ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆè¡¨ç¤º
selected_incident_candidate = None

st.markdown("### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
col1, col2, col3 = st.columns(3)
with col1: st.metric("ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡", "98.5%", "é«˜åŠ¹ç‡ç¨¼åƒä¸­")
with col2: st.metric("ğŸ“¨ å‡¦ç†ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms) * 15 if alarms else 0}ä»¶", "æŠ‘åˆ¶æ¸ˆ")
with col3: st.metric("ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ", f"{len([c for c in analysis_results if c['prob'] > 0.6])}ä»¶", "å¯¾å‡¦ãŒå¿…è¦")
st.markdown("---")

df_data = []
# â˜…ä¿®æ­£: ã‚¹ãƒ©ã‚¤ã‚¹åˆ¶é™ã‚’æ’¤å»ƒ (å…¨ä»¶è¡¨ç¤º)
# éšå±¤ãƒ­ã‚¸ãƒƒã‚¯ã«ã‚ˆã‚Šã€é‡è¦ãªã‚‚ã®(Tieré«˜)ãŒå…ˆé ­ã«æ¥ã‚‹ãŸã‚ã€å¤§é‡ã«ã‚ã£ã¦ã‚‚å•é¡Œãªã„
for rank, cand in enumerate(analysis_results, 1):
    status = "âšª ç›£è¦–ä¸­"
    action = "ğŸ‘ï¸ é™è¦³"
    
    if cand['prob'] > 0.8:
        status = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
        action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
    elif cand['prob'] > 0.6:
        status = "ğŸŸ¡ è­¦å‘Š (è¢«ç–‘ç®‡æ‰€)"
        action = "ğŸ” è©³ç´°èª¿æŸ»ã‚’æ¨å¥¨"
    
    if "Network/Unreachable" in cand['type'] or "Network/Secondary" in cand['type']:
        status = "âš« å¿œç­”ãªã— (ä¸Šä½éšœå®³)"
        action = "â›” å¯¾å¿œä¸è¦ (ä¸Šä½å¾©æ—§å¾…ã¡)"

    candidate_text = f"ãƒ‡ãƒã‚¤ã‚¹: {cand['id']} / åŸå› : {cand['label']}"
    if cand.get('verification_log'):
        candidate_text += " [ğŸ” Active Probe: å¿œç­”ãªã—]"
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«Tierã‚’è¡¨ç¤ºï¼ˆæœ¬ç•ªã§ã¯æ¶ˆã—ã¦ã‚‚è‰¯ã„ï¼‰
    # candidate_text += f" (Tier: {cand.get('tier')})"

    df_data.append({
        "é †ä½": rank,
        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status,
        "æ ¹æœ¬åŸå› å€™è£œ": candidate_text,
        "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢": cand['prob'],
        "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
        "ID": cand['id'],
        "Type": cand['type']
    })

df = pd.DataFrame(df_data)
st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€å³å´ã«è©³ç´°åˆ†æã¨å¾©æ—§ãƒ—ãƒ©ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

event = st.dataframe(
    df,
    column_order=["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ ¹æœ¬åŸå› å€™è£œ", "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
    column_config={
        "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢": st.column_config.ProgressColumn("ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ (0-1.0)", format="%.2f", min_value=0, max_value=1),
    },
    use_container_width=True,
    hide_index=True,
    selection_mode="single-row",
    on_select="rerun"
)

if len(event.selection.rows) > 0:
    idx = event.selection.rows[0]
    sel_row = df.iloc[idx]
    for res in analysis_results:
        if res['id'] == sel_row['ID'] and res['type'] == sel_row['Type']:
            selected_incident_candidate = res
            break
else:
    selected_incident_candidate = analysis_results[0] if analysis_results else None


# 4. ç”»é¢åˆ†å‰²
col_map, col_chat = st.columns([1.2, 1])

# === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ã¨è¨ºæ–­ ===
with col_map:
    st.subheader("ğŸŒ Network Topology")
    
    current_root_node = None
    current_severity = "WARNING"
    
    if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
        current_root_node = TOPOLOGY.get(selected_incident_candidate["id"])
        if "Hardware/Physical" in selected_incident_candidate["type"] or "Critical" in selected_incident_candidate["type"] or "Silent" in selected_incident_candidate["type"]:
            current_severity = "CRITICAL"
        else:
            current_severity = "WARNING"

    elif target_device_id:
        current_root_node = TOPOLOGY.get(target_device_id)
        current_severity = root_severity

    st.graphviz_chart(render_topology(alarms, analysis_results), use_container_width=True)

    st.markdown("---")
    st.subheader("ğŸ› ï¸ Auto-Diagnostics")
    
    if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
        if not api_key:
            st.error("API Key Required")
        else:
            with st.status("Agent Operating...", expanded=True) as status:
                st.write("ğŸ”Œ Connecting to device...")
                target_node_obj = TOPOLOGY.get(target_device_id) if target_device_id else None
                
                res = run_diagnostic_simulation(selected_scenario, target_node_obj, api_key)
                st.session_state.live_result = res
                
                if res["status"] == "SUCCESS":
                    st.write("âœ… Log Acquired & Sanitized.")
                    status.update(label="Diagnostics Complete!", state="complete", expanded=False)
                    log_content = res.get('sanitized_log', "")
                    verification = verify_log_content(log_content)
                    st.session_state.verification_result = verification
                    st.session_state.trigger_analysis = True
                elif res["status"] == "SKIPPED":
                    status.update(label="No Action Required", state="complete")
                else:
                    st.write("âŒ Connection Failed.")
                    status.update(label="Diagnostics Failed", state="error")
            st.rerun()

    if st.session_state.live_result:
        res = st.session_state.live_result
        if res["status"] == "SUCCESS":
            st.markdown("#### ğŸ“„ Diagnostic Results")
            with st.container(border=True):
                if selected_incident_candidate and selected_incident_candidate.get("verification_log"):
                    st.caption("ğŸ¤– Active Probe / Verification Log")
                    st.code(selected_incident_candidate["verification_log"], language="text")
                    st.divider()

                if st.session_state.verification_result:
                    v = st.session_state.verification_result
                    c1, c2, c3 = st.columns(3)
                    c1.metric("Ping Status", v.get('ping_status'))
                    c2.metric("Interface", v.get('interface_status'))
                    c3.metric("Hardware", v.get('hardware_status'))
                
                st.divider()
                st.caption("ğŸ”’ Raw Logs (Sanitized)")
                st.code(res["sanitized_log"], language="text")
        elif res["status"] == "ERROR":
            st.error(f"è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {res.get('error')}")

# === å³ã‚«ãƒ©ãƒ : åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===
with col_chat:
    st.subheader("ğŸ“ AI Analyst Report")
    
    if selected_incident_candidate:
        cand = selected_incident_candidate
        
        # --- A. çŠ¶æ³å ±å‘Š (Situation Report) ---
        if "generated_report" not in st.session_state or st.session_state.generated_report is None:
            st.info(f"ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¸æŠä¸­: **{cand['id']}** ({cand['label']})")
            
            if api_key and selected_scenario != "æ­£å¸¸ç¨¼åƒ":
                if st.button("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)"):
                    
                    report_container = st.empty()
                    target_conf = load_config_by_id(cand['id'])
                    
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel("gemma-3-12b-it")
                    
                    verification_context = cand.get("verification_log", "ç‰¹ã«ãªã—")
                    
                    prompt = f"""
                    ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ç›£è¦–ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
                    ä»¥ä¸‹ã®éšœå®³ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã«ã¤ã„ã¦ã€é¡§å®¢å‘ã‘ã®ã€Œè©³ç´°ãªçŠ¶æ³å ±å‘Šãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
                    
                    ã€å…¥åŠ›æƒ…å ±ã€‘
                    - ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª: {selected_scenario}
                    - æ ¹æœ¬åŸå› å€™è£œ: {cand['id']} ({cand['label']})
                    - ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {cand['prob']*100:.0f}
                    
                    ã€â˜…é‡è¦: AIã«ã‚ˆã‚‹èƒ½å‹•çš„è¨ºæ–­çµæœ (Reasoning)ã€‘
                    ã‚·ã‚¹ãƒ†ãƒ ã¯ã‚¢ãƒ©ãƒ¼ãƒ ã ã‘ã§ãªãã€ä»¥ä¸‹ã®èƒ½å‹•çš„ãªç¢ºèªã‚’è¡Œã„ã¾ã—ãŸã€‚ã“ã®å†…å®¹ã‚’ã€Œå¯¾å¿œã€ã‚„ã€Œç‰¹å®šæ ¹æ‹ ã€ã«å«ã‚ã¦ãã ã•ã„ã€‚
                    {verification_context}

                    - å¯¾è±¡æ©Ÿå™¨Config: 
                    {target_conf[:1500]} (æŠœç²‹)

                    ã€é‡è¦: å‡ºåŠ›å½¢å¼ã€‘
                    1. HTMLã‚¿ã‚°(brãªã©)ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚æ”¹è¡Œã¯Markdownã®æ¨™æº–çš„ãªç©ºè¡Œï¼ˆã‚¨ãƒ³ã‚¿ãƒ¼2å›ï¼‰ã§è¡Œã£ã¦ãã ã•ã„ã€‚
                    2. è¦‹å‡ºã—ï¼ˆ###ï¼‰ã®å‰å¾Œã«ã¯å¿…ãšç©ºè¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
                    
                    æ§‹æˆ:
                    ### çŠ¶æ³å ±å‘Šï¼š{cand['id']}
                    
                    **1. éšœå®³æ¦‚è¦**
                    (æ¦‚è¦è¨˜è¿°)
                    
                    **2. å½±éŸ¿**
                    (å½±éŸ¿è¨˜è¿°)
                    
                    **3. è©³ç´°æƒ…å ±**
                    (æ©Ÿå™¨æƒ…å ±ãªã©)
                    
                    **4. å¯¾å¿œã¨ç‰¹å®šæ ¹æ‹ **
                    (â˜…ã“ã“ã«èƒ½å‹•çš„è¨ºæ–­ã®çµæœã‚’åæ˜ ã—ã¦è¨˜è¿°)
                    
                    **5. ä»Šå¾Œã®å¯¾å¿œ**
                    (ä»Šå¾Œ)
                    """
                    
                    try:
                        response = generate_content_with_retry(model, prompt, stream=True)
                        full_text = ""
                        for chunk in response:
                            if chunk.candidates[0].finish_reason == 1: 
                                pass 
                            elif chunk.candidates[0].finish_reason == 3: 
                                full_text = "âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå®‰å…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Šãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚åˆ¥ã®ã‚·ãƒŠãƒªã‚ªã‚’è©¦ã—ã¦ãã ã•ã„ã€‚"
                                break
                            else:
                                full_text += chunk.text
                                report_container.markdown(full_text)
                        
                        if not full_text: full_text = "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆç©ºã®å¿œç­”ï¼‰ã€‚"
                        st.session_state.generated_report = full_text
                        st.session_state.last_report_cand_id = cand['id']
                        
                    except Exception as e:
                        err_msg = f"Report Generation Error: {str(e)}"
                        st.session_state.generated_report = err_msg
                        st.error("ç¾åœ¨ã€AIãƒ¢ãƒ‡ãƒ«ãŒæ··é›‘ã—ã¦ã„ã¾ã™ (503 Error)ã€‚æ™‚é–“ã‚’ç½®ã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        else:
            st.markdown(st.session_state.generated_report)
            if st.button("ğŸ”„ ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ"):
                st.session_state.generated_report = None
                st.rerun()

    # --- B. è‡ªå‹•ä¿®å¾© & ãƒãƒ£ãƒƒãƒˆ ---
    st.markdown("---")
    st.subheader("ğŸ¤– Remediation & Chat")

    if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
        st.markdown(f"""
        <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
            <strong>âœ… AI Analysis Completed</strong><br>
            ç‰¹å®šã•ã‚ŒãŸåŸå›  <b>{selected_incident_candidate['id']}</b> ã«å¯¾ã™ã‚‹å¾©æ—§æ‰‹é †ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br>
            (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}</span>)
        </div>
        """, unsafe_allow_html=True)

        if "remediation_plan" not in st.session_state:
            if st.button("âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"):
                 if not api_key: st.error("API Key Required")
                 else:
                    with st.spinner("Generating plan..."):
                        t_node = TOPOLOGY.get(selected_incident_candidate["id"])
                        plan_md = generate_remediation_commands(
                            selected_scenario, 
                            f"Identified Root Cause: {selected_incident_candidate['label']}", 
                            t_node, api_key
                        )
                        st.session_state.remediation_plan = plan_md
                        st.rerun()
        
        if "remediation_plan" in st.session_state:
            with st.container(border=True):
                st.info("AI Generated Recovery Procedure")
                st.markdown(st.session_state.remediation_plan)
            
            col_exec1, col_exec2 = st.columns(2)
            
            with col_exec1:
                if st.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary"):
                    if not api_key:
                        st.error("API Key Required")
                    else:
                        with st.status("Autonomic Remediation in progress...", expanded=True) as status:
                            st.write("âš™ï¸ Applying Configuration...")
                            time.sleep(1.5) 
                            
                            st.write("ğŸ” Running Verification Commands...")
                            target_node_obj = TOPOLOGY.get(selected_incident_candidate["id"])
                            verification_log = generate_fake_log_by_ai("æ­£å¸¸ç¨¼åƒ", target_node_obj, api_key)
                            st.session_state.verification_log = verification_log
                            
                            st.write("âœ… Verification Completed.")
                            status.update(label="Process Finished", state="complete", expanded=False)
                        
                        st.success("Remediation Process Finished.")

            with col_exec2:
                 if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                    del st.session_state.remediation_plan
                    st.session_state.verification_log = None
                    st.rerun()
            
            if st.session_state.get("verification_log"):
                st.markdown("#### ğŸ” Post-Fix Verification Logs")
                st.code(st.session_state.verification_log, language="text")
                
                is_success = "up" in st.session_state.verification_log.lower() or "ok" in st.session_state.verification_log.lower()
                
                if is_success:
                    st.balloons()
                    st.success("âœ… System Recovered Successfully!")
                else:
                    st.warning("âš ï¸ Verification indicates potential issues. Please check manually.")

                if st.button("ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¦ãƒªã‚»ãƒƒãƒˆ"):
                    del st.session_state.remediation_plan
                    st.session_state.verification_log = None
                    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
                    st.rerun()
    else:
        if selected_incident_candidate:
            score = selected_incident_candidate['prob'] * 100
            st.warning(f"""
            âš ï¸ **è‡ªå‹•ä¿®å¾©ã¯ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã¾ã™**
            ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã¯ **{score:.0f}** ã§ã™ã€‚
            èª¤æ“ä½œé˜²æ­¢ã®ãŸã‚ã€ã‚¹ã‚³ã‚¢ãŒ 60 ä»¥ä¸Šã®æ™‚ã®ã¿è‡ªå‹•ä¿®å¾©ãƒœã‚¿ãƒ³ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚
            """)

    # ãƒãƒ£ãƒƒãƒˆ (å¸¸æ™‚è¡¨ç¤º)
    with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
        if st.session_state.chat_session is None and api_key and selected_scenario != "æ­£å¸¸ç¨¼åƒ":
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemma-3-12b-it")
            st.session_state.chat_session = model.start_chat(history=[])

        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        if prompt := st.chat_input("Ask details..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            if st.session_state.chat_session:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        res_container = st.empty()
                        response = generate_content_with_retry(st.session_state.chat_session.model, prompt, stream=True)
                        if response:
                            full_response = ""
                            for chunk in response:
                                full_response += chunk.text
                                res_container.markdown(full_response)
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                        else:
                            st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ãƒ™ã‚¤ã‚ºæ›´æ–°ãƒˆãƒªã‚¬ãƒ¼ (è¨ºæ–­å¾Œ)
if st.session_state.trigger_analysis and st.session_state.live_result:
    if st.session_state.verification_result:
        pass
    st.session_state.trigger_analysis = False
    st.rerun()
