import streamlit as st
import graphviz
import os
import google.generativeai as genai

# ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ­ã‚¸ãƒƒã‚¯ãƒ»é‹ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm
# â˜…é‡è¦: å®Ÿæ©Ÿæ¥ç¶šã®ä»£ã‚ã‚Šã«ã‚¹ã‚¿ãƒ–(ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™
from network_ops import run_diagnostic_simulation

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Live", page_icon="âš¡", layout="wide")

# --- é–¢æ•°: ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®ç”Ÿæˆ (å†—é•·æ§‹æˆå¯¾å¿œ) ---
def render_topology(alarms, root_cause_node):
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    alarmed_ids = {a.device_id for a in alarms}
    
    # ãƒãƒ¼ãƒ‰æç”»
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9" # Default Green
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"
        
        if root_cause_node and node_id == root_cause_node.id:
            color = "#ffcdd2" # Root Cause Red
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif node_id in alarmed_ids:
            color = "#fff9c4" # Alarm Yellow
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    # ã‚¨ãƒƒã‚¸æç”»
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            
            # è¦ªãŒHAã‚°ãƒ«ãƒ¼ãƒ—ã®å ´åˆã€ç›¸æ–¹ã‹ã‚‰ã‚‚ç·šã‚’å¼•ã
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() 
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph

# --- é–¢æ•°: Configè‡ªå‹•èª­ã¿è¾¼ã¿ (IDãƒ™ãƒ¼ã‚¹) ---
def load_config_by_id(device_id):
    path = f"configs/{device_id}.txt"
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            return None
    return None

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity AI Agent (Live Demo)")

# APIã‚­ãƒ¼å–å¾—
api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš¡ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    selected_scenario = st.radio(
        "ã‚·ãƒŠãƒªã‚ª:", 
        ("æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³", "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    )
    
    st.markdown("---")
    if api_key:
        st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
    st.session_state.messages = []
    st.session_state.chat_session = None 
    st.session_state.live_result = None

# ã‚·ãƒŠãƒªã‚ªå¤‰æ›´æ™‚ã®ãƒªã‚»ãƒƒãƒˆå‡¦ç†
if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []
    st.session_state.chat_session = None
    st.session_state.live_result = None
    st.rerun()

# --- ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨) ---
alarms = []
if selected_scenario == "1. WANå…¨å›ç·šæ–­":
    alarms = [
        Alarm("WAN_ROUTER_01", "Interface Down", "CRITICAL"),
        Alarm("FW_01_PRIMARY", "Gateway Unreachable", "WARNING"),
        Alarm("FW_01_SECONDARY", "Gateway Unreachable", "WARNING"),
        Alarm("CORE_SW_01", "Uplink Down", "WARNING"),
        Alarm("AP_01", "Unreachable", "CRITICAL")
    ]
elif selected_scenario == "2. FWç‰‡ç³»éšœå®³":
    alarms = [Alarm("FW_01_PRIMARY", "Heartbeat Loss", "WARNING")]
elif selected_scenario == "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³":
    alarms = [Alarm("AP_01", "Connection Lost", "CRITICAL"), Alarm("AP_02", "Connection Lost", "CRITICAL")]

# æ¨è«–å®Ÿè¡Œ (é€šå¸¸ã‚·ãƒŠãƒªã‚ªã®å ´åˆ)
root_cause = None
inference_result = None
reason = ""

if alarms:
    engine = CausalInferenceEngine(TOPOLOGY)
    inference_result = engine.analyze_alarms(alarms)
    root_cause = inference_result.root_cause_node
    reason = inference_result.root_cause_reason

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col1, col2 = st.columns([1, 1])

# å·¦ã‚«ãƒ©ãƒ ï¼šãƒˆãƒãƒ­ã‚¸ãƒ¼ ï¼† è‡ªå¾‹èª¿æŸ»UI
with col1:
    st.subheader("Network Status")
    st.graphviz_chart(render_topology(alarms, root_cause), use_container_width=True)
    
    # ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤º
    if root_cause:
        st.markdown(
            f'<div style="color: #d32f2f; font-weight: bold; font-size: 15px; background-color: #fdecea; padding: 10px; border-radius: 5px;">'
            f'ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆï¼š{root_cause.id} ãƒ€ã‚¦ãƒ³'
            f'</div>', 
            unsafe_allow_html=True
        )
        st.caption(f"ç†ç”±: {reason}")
    
    # Liveãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®UI
    is_live_mode = (selected_scenario == "4. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­")
    
    if is_live_mode or root_cause: # éšœå®³æ™‚ã¯å¸¸ã«èª¿æŸ»ãƒœã‚¿ãƒ³ã‚’å‡ºã—ã¦ã‚‚è‰¯ã„ãŒã€ä»Šå›ã¯Liveãƒ¢ãƒ¼ãƒ‰å¼·èª¿
        st.markdown("---")
        st.info("ğŸ›  **è‡ªå¾‹èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**")
        
        # ãƒœã‚¿ãƒ³: è¨ºæ–­å®Ÿè¡Œ (ã‚¹ã‚¿ãƒ–é–¢æ•°ã‚’å‘¼ã³å‡ºã—)
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Simulation)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status:
                    st.write("ğŸ”Œ Initiating connection simulation...")
                    # ã‚¹ã‚¿ãƒ–é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦çµæœã‚’å–å¾—
                    res = run_diagnostic_simulation(selected_scenario)
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Data retrieved.")
                        status.update(label="Complete!", state="complete", expanded=False)
                    else:
                        st.write("âŒ Connection Failed (As expected in failure scenario).")
                        status.update(label="Target Unreachable", state="error", expanded=False)

        # è¨ºæ–­çµæœã®è¡¨ç¤º
        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒŠãƒ¼ (ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ1)
                st.success("ğŸ›¡ï¸ **Data Sanitized**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒã‚¹ã‚¯å‡¦ç†ã—ã¾ã—ãŸã€‚")
                
                with st.expander("ğŸ“„ å–å¾—ãƒ­ã‚° (Sanitized View)", expanded=True):
                    st.code(res["sanitized_log"], language="text")
            else:
                st.error(f"è¨ºæ–­çµæœ: {res['error']}")
                st.caption("â€»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã“ã®æ¥ç¶šã‚¨ãƒ©ãƒ¼è‡ªä½“ã‚’ã€è¨ºæ–­æƒ…å ±ã€ã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚")

# å³ã‚«ãƒ©ãƒ ï¼šAIãƒãƒ£ãƒƒãƒˆ (ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œ)
with col2:
    st.subheader("AI Analyst Report")

    # APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    if not api_key:
        st.error("APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        st.stop()

    # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– (åˆå›ã®ã¿)
    # LiveçµæœãŒã‚ã‚‹å ´åˆã€ã¾ãŸã¯æ¨è«–çµæœãŒã‚ã‚‹å ´åˆã«èµ·å‹•
    should_start_chat = (st.session_state.chat_session is None) and (selected_scenario != "æ­£å¸¸ç¨¼åƒ")
    
    if should_start_chat:
        genai.configure(api_key=api_key)
        
        # è¨­å®š: Gemini 2.0 Flash, æ¸©åº¦0
        generation_config = {
            "temperature": 0.0,
            "max_output_tokens": 1500,
        }
        model = genai.GenerativeModel("gemini-2.0-flash", generation_config=generation_config)
        
        # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ ---
        system_prompt = ""
        
        # A. Liveè¨ºæ–­çµæœãŒã‚ã‚‹å ´åˆ (Liveãƒ¢ãƒ¼ãƒ‰å„ªå…ˆ)
        if st.session_state.live_result:
            live_data = st.session_state.live_result
            system_prompt = f"""
            ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚ä»¥ä¸‹ã®è¨ºæ–­çµæœã«åŸºã¥ãã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®çµŒç·¯ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚

            ã€è¨ºæ–­å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‘
            ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}
            è©³ç´°/ãƒ­ã‚°: {live_data.get('sanitized_log') or live_data.get('error')}
            æ¨è«–ã•ã‚ŒãŸåŸå› : {reason if reason else "å®Ÿæ©Ÿèª¿æŸ»ãƒ¢ãƒ¼ãƒ‰"}

            ã€å‡ºåŠ›è¦ä»¶ã€‘
            ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
            
            ### ğŸ›  ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
            
            **1. ãƒ‡ãƒ¼ã‚¿ä¿å…¨ã¨æ¥ç¶šç¢ºèª:**
            æ¥ç¶šè©¦è¡ŒãŠã‚ˆã³ãƒ­ã‚°å–å¾—ã‚’å®Ÿæ–½ã€‚
            â†’ **çµæœ: {live_data['status']}** (ğŸ›¡ï¸ æ©Ÿå¯†æƒ…å ±ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿)
            
            **2. è©³ç´°åˆ†æ:**
            [æ¥ç¶šã§ããŸå ´åˆã¯ãƒ­ã‚°å†…å®¹ï¼ˆConfig/Interfaceï¼‰ã®åˆ†æã€ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯è¦å› æ¨æ¸¬]
            â†’ [åˆ†æçµæœ]
            
            **3. ç‰©ç†/ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ç¢ºèª:**
            [çŠ¶æ³ã«å¿œã˜ãŸæ¨è«–]
            â†’ [åˆ†æçµæœ]
            
            ---
            **æœ€çµ‚åˆ¤å®š:** [çµè«–]
            """

        # B. é€šå¸¸ã®æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ (Liveè¨ºæ–­å‰)
        elif root_cause:
            # Configèª­ã¿è¾¼ã¿
            config_content = load_config_by_id(root_cause.id)
            
            system_prompt = f"""
            ã‚ãªãŸã¯AIOpsã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®éšœå®³ã«ã¤ã„ã¦å ±å‘Šã—ã¦ãã ã•ã„ã€‚
            
            æ ¹æœ¬åŸå› : {root_cause.id} ({root_cause.type})
            ç†ç”±: {inference_result.root_cause_reason}
            """
            
            if config_content:
                system_prompt += f"\nã€Configã‚ã‚Šã€‘\n{config_content}\nä¸Šè¨˜è¨­å®šã«åŸºã¥ãã€å…·ä½“çš„ãªç¢ºèªã‚³ãƒãƒ³ãƒ‰ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
            else:
                system_prompt += "\nã€Configãªã—ã€‘\nä¸€èˆ¬çš„ãªå¾©æ—§æ‰‹é †ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
            
            system_prompt += "\nãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: ç·Šæ€¥åº¦(çµµæ–‡å­—)ã€çŠ¶æ³è¦ç´„ã€æ¨å¥¨SOPã®é †ã§å‡ºåŠ›ã€‚"

        # ãƒãƒ£ãƒƒãƒˆé–‹å§‹
        if system_prompt:
            history = [{"role": "user", "parts": [system_prompt]}]
            chat = model.start_chat(history=history)
            
            try:
                # æœ€åˆã®åˆ†æã‚’å®Ÿè¡Œ
                with st.spinner("Gemini is analyzing..."):
                    response = chat.send_message("ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
                    st.session_state.chat_session = chat
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")

    # --- ãƒãƒ£ãƒƒãƒˆUIã®è¡¨ç¤º (ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠ) ---
    chat_container = st.container(height=600)
    
    with chat_container:
        # å±¥æ­´è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # å…¥åŠ›æ¬„ (ã‚³ãƒ³ãƒ†ãƒŠã®å¤–ã«é…ç½®ã—ã¦å›ºå®š)
    if prompt := st.chat_input("AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æŒ‡ç¤º..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å³æ™‚è¡¨ç¤º
        with chat_container:
            with st.chat_message("user"):
                st.markdown(prompt)

        # AIå¿œç­”
        if st.session_state.chat_session:
            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        try:
                            res = st.session_state.chat_session.send_message(prompt)
                            st.markdown(res.text)
                            st.session_state.messages.append({"role": "assistant", "content": res.text})
                        except Exception as e:
                            st.error(f"Error: {e}")
