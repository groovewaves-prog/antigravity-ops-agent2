import streamlit as st
import graphviz
import os
import time
import google.generativeai as genai
import json

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import run_diagnostic_simulation, generate_remediation_commands, predict_initial_symptoms, generate_fake_log_by_ai
from verifier import verify_log_content, format_verification_report
from dashboard import render_intelligent_alarm_viewer
from bayes_engine import BayesianRCA

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Autonomous", page_icon="âš¡", layout="wide")

# ==========================================
# é–¢æ•°å®šç¾©
# ==========================================
def find_target_node_id(topology, node_type=None, layer=None, keyword=None):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰æ¡ä»¶ã«åˆã†ãƒãƒ¼ãƒ‰IDã‚’æ¤œç´¢"""
    for node_id, node in topology.items():
        if node_type and node.type != node_type: continue
        if layer and node.layer != layer: continue
        if keyword:
            hit = False
            if keyword in node_id: hit = True
            for v in node.metadata.values():
                if isinstance(v, str) and keyword in v: hit = True
            if not hit: continue
        return node_id
    return None

def load_config_by_id(device_id):
    """configsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    possible_paths = [f"configs/{device_id}.txt", f"{device_id}.txt"]
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                pass
    return "Config file not found."

def render_topology(alarms, root_cause_node, root_severity="CRITICAL"):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®æç”»"""
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    alarm_map = {a.device_id: a for a in alarms}
    alarmed_ids = set(alarm_map.keys())
    
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9"
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"
        
        red_type = node.metadata.get("redundancy_type")
        if red_type: label += f"\n[{red_type} Redundancy]"
        vendor = node.metadata.get("vendor")
        if vendor: label += f"\n[{vendor}]"

        if root_cause_node and node_id == root_cause_node.id:
            this_alarm = alarm_map.get(node_id)
            node_severity = this_alarm.severity if this_alarm else root_severity
            if node_severity == "CRITICAL": color = "#ffcdd2"
            elif node_severity == "WARNING": color = "#fff9c4"
            else: color = "#e8f5e9"
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif node_id in alarmed_ids:
            color = "#fff9c4" 
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() 
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity Autonomous Agent")

api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš¡ Scenario Controller")
    SCENARIO_MAP = {
        "åŸºæœ¬ãƒ»åºƒåŸŸéšœå®³": ["æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"],
        "WAN Router": ["4. [WAN] é›»æºéšœå®³ï¼šç‰‡ç³»", "5. [WAN] é›»æºéšœå®³ï¼šä¸¡ç³»", "6. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°", "7. [WAN] FANæ•…éšœ", "8. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "Firewall (Juniper)": ["9. [FW] é›»æºéšœå®³ï¼šç‰‡ç³»", "10. [FW] é›»æºéšœå®³ï¼šä¸¡ç³»", "11. [FW] FANæ•…éšœ", "12. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "L2 Switch": ["13. [L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»", "14. [L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»", "15. [L2SW] FANæ•…éšœ", "16. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "Live Mode": ["99. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­"]
    }
    selected_category = st.selectbox("å¯¾è±¡ã‚«ãƒ†ã‚´ãƒª:", list(SCENARIO_MAP.keys()))
    selected_scenario = st.radio("ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª:", SCENARIO_MAP[selected_category])
    st.markdown("---")
    if api_key: st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† ---
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"

# å¤‰æ•°åˆæœŸåŒ–
for key in ["live_result", "messages", "chat_session", "trigger_analysis", "verification_result", "generated_report", "verification_log"]:
    if key not in st.session_state:
        st.session_state[key] = None if key != "messages" and key != "trigger_analysis" else ([] if key == "messages" else False)

# ã‚·ãƒŠãƒªã‚ªåˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒªã‚»ãƒƒãƒˆ
if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []      
    st.session_state.chat_session = None 
    st.session_state.live_result = None 
    st.session_state.trigger_analysis = False
    st.session_state.verification_result = None
    st.session_state.generated_report = None
    st.session_state.verification_log = None 
    if "remediation_plan" in st.session_state: del st.session_state.remediation_plan
    if "bayes_engine" in st.session_state: del st.session_state.bayes_engine
    st.rerun()

# ==========================================
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================
alarms = []
root_severity = "CRITICAL"
target_device_id = None
is_live_mode = False

# 1. ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
if "Live" in selected_scenario: is_live_mode = True
elif "WANå…¨å›ç·šæ–­" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    if target_device_id: alarms = simulate_cascade_failure(target_device_id, TOPOLOGY)
elif "FWç‰‡ç³»éšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    if target_device_id:
        alarms = [Alarm(target_device_id, "Heartbeat Loss", "WARNING")]
        root_severity = "WARNING"
elif "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="SWITCH", layer=4)
    if target_device_id:
        child_nodes = [nid for nid, n in TOPOLOGY.items() if n.parent_id == target_device_id]
        alarms = [Alarm(child, "Connection Lost", "CRITICAL") for child in child_nodes]
else:
    if "[WAN]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    elif "[FW]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    elif "[L2SW]" in selected_scenario: target_device_id = find_target_node_id(TOPOLOGY, node_type="SWITCH", layer=4)

    if target_device_id:
        if "é›»æºéšœå®³ï¼šç‰‡ç³»" in selected_scenario:
            alarms = [Alarm(target_device_id, "Power Supply 1 Failed", "WARNING")]
            root_severity = "WARNING"
        elif "é›»æºéšœå®³ï¼šä¸¡ç³»" in selected_scenario:
            if "FW" in target_device_id:
                alarms = [Alarm(target_device_id, "Power Supply: Dual Loss (Device Down)", "CRITICAL")]
            else:
                alarms = simulate_cascade_failure(target_device_id, TOPOLOGY, "Power Supply: Dual Loss (Device Down)")
            root_severity = "CRITICAL"
        elif "BGP" in selected_scenario:
            alarms = [Alarm(target_device_id, "BGP Flapping", "WARNING")]
            root_severity = "WARNING"
        elif "FAN" in selected_scenario:
            alarms = [Alarm(target_device_id, "Fan Fail", "WARNING")]
            root_severity = "WARNING"
        elif "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
            alarms = [Alarm(target_device_id, "Memory High", "WARNING")]
            root_severity = "WARNING"

# 2. ãƒ™ã‚¤ã‚ºã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ– (AIè‡ªå‹•æ¨è«–)
if "bayes_engine" not in st.session_state:
    st.session_state.bayes_engine = BayesianRCA(TOPOLOGY)
    
    if selected_scenario != "æ­£å¸¸ç¨¼åƒ" and api_key:
        initial_symptoms = predict_initial_symptoms(selected_scenario, api_key)
        if initial_symptoms.get("alarm"):
            st.session_state.bayes_engine.update_probabilities("alarm", initial_symptoms["alarm"])
        if initial_symptoms.get("ping") == "NG":
            st.session_state.bayes_engine.update_probabilities("ping", "NG")
        if initial_symptoms.get("log"):
            st.session_state.bayes_engine.update_probabilities("log", initial_symptoms["log"])

# 3. ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆè¡¨ç¤º
selected_incident_candidate = None
if "bayes_engine" in st.session_state:
    # â˜…å¤‰æ›´ç‚¹: alarmsã‚’æ¸¡ã—ã¦æ•°å­—ã‚’è¨ˆç®—ã•ã›ã‚‹
    selected_incident_candidate = render_intelligent_alarm_viewer(
        st.session_state.bayes_engine, 
        selected_scenario,
        alarms
    )

# 4. ç”»é¢åˆ†å‰²
col_map, col_chat = st.columns([1.2, 1])

# === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ã¨è¨ºæ–­ ===
with col_map:
    st.subheader("ğŸŒ Network Topology")
    
    current_root_node = None
    current_severity = "WARNING"
    
    if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
        current_root_node = TOPOLOGY.get(selected_incident_candidate["id"])
        current_severity = "CRITICAL"
    elif target_device_id:
        current_root_node = TOPOLOGY.get(target_device_id)
        current_severity = root_severity

    st.graphviz_chart(render_topology(alarms, current_root_node, current_severity), use_container_width=True)

    st.markdown("---")
    st.subheader("ğŸ› ï¸ Auto-Diagnostics")
    
    if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
        if not api_key:
            st.error("API Key Required")
        else:
            with st.status("Agent Operating...", expanded=True) as status:
                st.write("ğŸ”Œ Connecting to device...")
                target_node_obj = TOPOLOGY.get(target_device_id) if target_device_id else None
                
                res = run_diagnostic_simulation(selected_scenario, target_node_obj, api_key)
                st.session_state.live_result = res
                
                if res["status"] == "SUCCESS":
                    st.write("âœ… Log Acquired & Sanitized.")
                    status.update(label="Diagnostics Complete!", state="complete", expanded=False)
                    log_content = res.get('sanitized_log', "")
                    verification = verify_log_content(log_content)
                    st.session_state.verification_result = verification
                    st.session_state.trigger_analysis = True
                elif res["status"] == "SKIPPED":
                    status.update(label="No Action Required", state="complete")
                else:
                    st.write("âŒ Connection Failed.")
                    status.update(label="Diagnostics Failed", state="error")
            st.rerun()

    if st.session_state.live_result:
        res = st.session_state.live_result
        if res["status"] == "SUCCESS":
            st.markdown("#### ğŸ“„ Diagnostic Results")
            with st.container(border=True):
                # è‡ªå‹•æ¤œè¨¼çµæœ
                if st.session_state.verification_result:
                    v = st.session_state.verification_result
                    c1, c2, c3 = st.columns(3)
                    c1.metric("Ping Status", v.get('ping_status'))
                    c2.metric("Interface", v.get('interface_status'))
                    c3.metric("Hardware", v.get('hardware_status'))
                
                st.divider()
                # ãƒ­ã‚°å‡ºåŠ›
                st.caption("ğŸ”’ Raw Logs (Sanitized)")
                st.code(res["sanitized_log"], language="text")
        elif res["status"] == "ERROR":
            st.error(f"è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {res.get('error')}")

# === å³ã‚«ãƒ©ãƒ : åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ===
with col_chat:
    st.subheader("ğŸ“ AI Analyst Report")
    
    # --- A. çŠ¶æ³å ±å‘Š (Situation Report) - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ ---
    if selected_incident_candidate:
        cand = selected_incident_candidate
        
        # 1. ã¾ã ãƒ¬ãƒãƒ¼ãƒˆãŒæœªç”Ÿæˆã€ã‹ã¤ã‚·ãƒŠãƒªã‚ªãŒæ­£å¸¸ä»¥å¤–ãªã‚‰ç”Ÿæˆã™ã‚‹
        if "generated_report" not in st.session_state or st.session_state.generated_report is None:
            if api_key and selected_scenario != "æ­£å¸¸ç¨¼åƒ":
                
                report_container = st.empty()
                
                target_conf = load_config_by_id(cand['id'])
                
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel("gemma-3-12b-it")
                
                # â˜…ä¿®æ­£ç‚¹: è¡¨ç¤ºå´©ã‚Œã‚’é˜²ããŸã‚ã®å¼·åŠ›ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = f"""
                ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ç›£è¦–ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
                ä»¥ä¸‹ã®éšœå®³ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã«ã¤ã„ã¦ã€é¡§å®¢å‘ã‘ã®ã€Œè©³ç´°ãªçŠ¶æ³å ±å‘Šãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
                
                ã€å…¥åŠ›æƒ…å ±ã€‘
                - ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª: {selected_scenario}
                - æ ¹æœ¬åŸå› å€™è£œ: {cand['id']} ({cand['type']})
                - AIç¢ºä¿¡åº¦: {cand['prob']:.1%}
                - å¯¾è±¡æ©Ÿå™¨Config: 
                {target_conf[:1500]} (æŠœç²‹)

                ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¦ä»¶ã€‘
                Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚
                
                **é‡è¦äº‹é …:**
                1. è¦‹å‡ºã—(###)ã‚„å¤ªå­—(**)ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€**ãã®å‰å¾Œã«ã¯å¿…ãšç©ºç™½è¡Œï¼ˆæ”¹è¡Œï¼‰ã‚’2ã¤å…¥ã‚Œã¦ãã ã•ã„ã€‚** ã“ã‚Œã‚’å®ˆã‚‰ãªã„ã¨è¡¨ç¤ºãŒå´©ã‚Œã¾ã™ã€‚
                2. ç®‡æ¡æ›¸ããƒªã‚¹ãƒˆã®å‰ã«ã‚‚å¿…ãšæ”¹è¡Œã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
                
                æ§‹æˆ:
                ### çŠ¶æ³å ±å‘Šï¼š{cand['id']}
                
                **1. éšœå®³æ¦‚è¦**
                
                (ã“ã“ã«æ¦‚è¦)
                
                **2. å½±éŸ¿**
                
                (ã“ã“ã«å½±éŸ¿)
                
                **3. è©³ç´°æƒ…å ±**
                
                (æ©Ÿå™¨åã€HAã‚°ãƒ«ãƒ¼ãƒ—ã€éšœå®³å†…å®¹ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€è¨­å®šæƒ…å ±ãªã©)
                
                **4. å¯¾å¿œ**
                
                (å¯¾å¿œç­–)
                
                **5. ä»Šå¾Œã®å¯¾å¿œ**
                
                (ä»Šå¾Œã®äºˆå®š)
                """
                
                try:
                    response = model.generate_content(prompt, stream=True)
                    full_text = ""
                    for chunk in response:
                        full_text += chunk.text
                        report_container.markdown(full_text)
                    st.session_state.generated_report = full_text
                except Exception as e:
                    st.session_state.generated_report = f"Report Generation Error: {e}"
            else:
                 st.session_state.generated_report = "ç›£è¦–ä¸­... ç•°å¸¸ã¯æ¤œçŸ¥ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

        # ç”Ÿæˆæ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
        elif st.session_state.generated_report:
             st.markdown(st.session_state.generated_report)
    
    # --- B. è‡ªå‹•ä¿®å¾© & ãƒãƒ£ãƒƒãƒˆ ---
    st.markdown("---")
    st.subheader("ğŸ¤– Remediation & Chat")

    if selected_incident_candidate and selected_incident_candidate["prob"] > 0.8:
        if "remediation_plan" not in st.session_state:
            if st.button("âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"):
                 if not api_key: st.error("API Key Required")
                 else:
                    with st.spinner("Generating plan..."):
                        t_node = TOPOLOGY.get(selected_incident_candidate["id"])
                        plan_md = generate_remediation_commands(
                            selected_scenario, 
                            f"Identified Root Cause: {selected_incident_candidate['type']}", 
                            t_node, api_key
                        )
                        st.session_state.remediation_plan = plan_md
                        st.rerun()
        
        if "remediation_plan" in st.session_state:
            with st.container(border=True):
                st.info("AI Generated Recovery Procedure")
                st.markdown(st.session_state.remediation_plan)
            
            # --- å¾©æ—§å®Ÿè¡Œã‚¨ãƒªã‚¢ ---
            col_exec1, col_exec2 = st.columns(2)
            
            with col_exec1:
                if st.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary"):
                    if not api_key:
                        st.error("API Key Required")
                    else:
                        with st.status("Autonomic Remediation in progress...", expanded=True) as status:
                            st.write("âš™ï¸ Applying Configuration...")
                            time.sleep(1.5) 
                            
                            st.write("ğŸ” Running Verification Commands...")
                            target_node_obj = TOPOLOGY.get(selected_incident_candidate["id"])
                            verification_log = generate_fake_log_by_ai("æ­£å¸¸ç¨¼åƒ", target_node_obj, api_key)
                            st.session_state.verification_log = verification_log
                            
                            st.write("âœ… Verification Completed.")
                            status.update(label="Process Finished", state="complete", expanded=False)
                        
                        st.success("Remediation Process Finished. Please check the verification logs below.")

            with col_exec2:
                 if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                    del st.session_state.remediation_plan
                    st.session_state.verification_log = None
                    st.rerun()
            
            # --- æ¤œè¨¼çµæœã®è¡¨ç¤º ---
            if st.session_state.get("verification_log"):
                st.markdown("#### ğŸ” Post-Fix Verification Logs")
                st.code(st.session_state.verification_log, language="text")
                
                is_success = "up" in st.session_state.verification_log.lower() or "ok" in st.session_state.verification_log.lower()
                
                if is_success:
                    st.balloons()
                    st.success("âœ… System Recovered Successfully!")
                else:
                    st.warning("âš ï¸ Verification indicates potential issues. Please check manually.")

                if st.button("ğŸ”„ æ‰‹å‹•æ¤œè¨¼ (Manual Verify)"):
                    with st.spinner("Re-running verification..."):
                        target_node_obj = TOPOLOGY.get(selected_incident_candidate["id"])
                        new_log = generate_fake_log_by_ai("æ­£å¸¸ç¨¼åƒ", target_node_obj, api_key)
                        st.session_state.verification_log = new_log
                        st.rerun()
                        
                if st.button("ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¦ãƒªã‚»ãƒƒãƒˆ"):
                    del st.session_state.remediation_plan
                    st.session_state.verification_log = None
                    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
                    st.rerun()

    # ãƒãƒ£ãƒƒãƒˆ (å¸¸æ™‚è¡¨ç¤º)
    with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
        if st.session_state.chat_session is None and api_key and selected_scenario != "æ­£å¸¸ç¨¼åƒ":
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemma-3-12b-it")
            st.session_state.chat_session = model.start_chat(history=[])

        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        if prompt := st.chat_input("Ask details..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            if st.session_state.chat_session:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        res_container = st.empty()
                        response = st.session_state.chat_session.send_message(prompt, stream=True)
                        full_response = ""
                        for chunk in response:
                            full_response += chunk.text
                            res_container.markdown(full_response)
                        st.session_state.messages.append({"role": "assistant", "content": full_response})

# ãƒ™ã‚¤ã‚ºæ›´æ–°ãƒˆãƒªã‚¬ãƒ¼ (è¨ºæ–­å¾Œ)
if st.session_state.trigger_analysis and st.session_state.live_result:
    if st.session_state.verification_result:
        v_res = st.session_state.verification_result
        if "NG" in v_res.get("ping_status", ""):
                st.session_state.bayes_engine.update_probabilities("ping", "NG")
        if "DOWN" in v_res.get("interface_status", ""):
                st.session_state.bayes_engine.update_probabilities("log", "Interface Down")
    st.session_state.trigger_analysis = False
    st.rerun()
